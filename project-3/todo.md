Project 3 TODO
==============

1 Mandatory

*  [X] 1 Train the 3-state model (from class) on parts 0-8 of the training data using training-by-counting.
    Show the obtained model parameters (transition, emission, and start probilities).

*  [X] 2 Redo step 1 with the 4-state model (from class). Recall that for this model, the given annotations does
    not correspond immediately to sequences of hidden states, as there are two states that we interpret as being in
    transmembrane helix (annotation M).

*  [X] 3 Make a 10-fold experiment using the 3-state model, training-by-counting, and Viterbi decoding for prediction.
    Show the AC compute by compare_tm_pred.py for each fold, and show the mean and variance of the ACs over all 10 folds.

*  [X] 4 Redo step 3 with the 4-state model.

*  [ ] 5 Redo step 3 and 4 using Posterior decoding. How does the results obtained by posterior decoding compare to the
    results obtained by Viterbi decoding?

*  [ ] 6 Redo steps 3-5 for any other models that you find relevant, e.g. the ones we talked about in class. What is the
    best AC (i.e. best mean over a 10-fold experiment) that you can obtain? How does your best model look like?

2 Optional

*  [ ] 7 Redo steps 3-6 using Viterbi-training instead of training-by-counting (i.e. you ignore the annotations in the
    training data.)

*  [ ] 8 Redo steps 3-6 using EM-training instead of training-by-counting.

*  [ ] 9 If you have implemented the forward and backward algorithms using both scaling and log-transform as explained in
    class, you can make a comparison of their running times, e.g. by measuring the time it takes to make the
    posterior decodings in the 10-fold experiments.

*  [ ] 10 Compare your best prediction method against the [THMMM program] (http://www.cbs.dtu.dk/services/TMHMM/)

3 Things to check

*  [ ] 1 Check from line 79 to the end of the function, I'm not sure if that's the way to store the results of the
    compare_tm_pred.py. We are storing the total_ac variable, with the sum of each sequences. To achieve that, now, in
    the file compare_pred, we have a function compute() which returns the same value that the function print_stats prints
    in the screen, so we can store the total_ac for each group of iterations and finally, in the line 105 of the main.py
    we can show the mean and the variance.
    I think it should be correct, because we have an improvement when we move from 3 states to 4

*  [ ] 2 Posterior performs worse than viterbi, I think we should expect that. At least, it also improves with 4 states


4 Explaining some things

*  [ ] 1 I've added some more functionalities to the model, basically the labels, because as the model now has other
    hidden states and not only i M o, we need to translate the new states to its equivalent, for example, from iMo to M.

*  [ ] 2 Fussines of python. It works mainly with pointers, so when we modified the sequence from 'iiMooo' to ['i','i',
    'iMo'...] to be able to work with more hidden states, we were actually modifying the input sequence, so now we
    have a checker to return the sequence to its original state. It basically checks if there are labels loaded in the
    model
*  [ ] 3 For the steps 3,4 and 5 we are using the same function, the nice thing is that we only need to specify the training
    method and the decoder object when we call the function, check the lines 125(for example) and 56 and 83 to see how
    it works
*  [ ] 4 Now, the function training, returns a new model generated by the training function and keeping the labels, if there
    were labels,



